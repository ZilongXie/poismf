{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson factorization\n",
    "\n",
    "This example notebook illustrates the usage of the [poismf](https://www.github.com/david-cortes/poismf) package for recommender systems with implicit feedback data using the [Last.FM 360k dataset](http://ocelma.net/MusicRecommendationDataset/index.html). The model is described in more detail in [Fast Non-Bayesian Poisson Factorization for Implicit-Feedback Recommendations](https://arxiv.org/abs/1811.01908).\n",
    "\n",
    "# Model description\n",
    "\n",
    "The basic idea is to take a sparse input matrix of counts $\\mathbf{X}_{m,n}$, which in this case is given by the number of times each user (row in the matrix) played each song (column in the matrix), and find an approximation as the product of two non-negative lower-dimensional latent factor matrices $\\mathbf{A}_{m,k}$ and $\\mathbf{B}_{n,k}$ by maximizing Poisson likelihood, i.e. fit a model:\n",
    "$$\n",
    "\\mathbf{X} \\sim \\text{Poisson}(\\mathbf{A} \\mathbf{B}^T)\n",
    "$$\n",
    "\n",
    "Which is then used to make predictions on the missing (zero-valued) entries, with the highest-predicted items for each user being the best candidates to recommend.\n",
    "\n",
    "The package offers different optimization methods which have different advantages in terms of speed and quality, and depending on the settings, is usually able to find good solutions in which the latent factors matrices $\\mathbf{A}$ and $\\mathbf{B}$ are sparse (i.e. most entries are exactly zero).\n",
    "** *\n",
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>betty blowtorch</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>f2fb0ff0-5679-42ec-a55c-15109ce6e320</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
       "      <td>melissa etheridge</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     UserId  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "\n",
       "                                 ItemId             Artist  Count  \n",
       "0  3bd73256-3905-4f3a-97e2-8b341527f805    betty blowtorch   2137  \n",
       "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320          die Ärzte   1099  \n",
       "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa  melissa etheridge    897  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "lfm = pd.read_table('usersha1-artmbid-artname-plays.tsv',\n",
    "                           sep='\\t', header=None, names=['UserId','ItemId', 'Artist','Count'])\n",
    "lfm.columns = ['UserId', 'ItemId', 'Artist', 'Count']\n",
    "lfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37425</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>152039</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>112365</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Count\n",
       "0       0   37425   2137\n",
       "1       0  152039   1099\n",
       "2       0  112365    897"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfm = lfm.drop('Artist', axis=1)\n",
    "lfm = lfm.loc[lfm.Count > 0]\n",
    "lfm['UserId'] = pd.Categorical(lfm.UserId).codes\n",
    "lfm['ItemId'] = pd.Categorical(lfm.ItemId).codes\n",
    "lfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.753565e+07\n",
       "mean     2.151932e+02\n",
       "std      6.144815e+02\n",
       "min      1.000000e+00\n",
       "25%      3.500000e+01\n",
       "50%      9.400000e+01\n",
       "75%      2.240000e+02\n",
       "max      4.191570e+05\n",
       "Name: Count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfm.Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a train-test split\n",
    "\n",
    "This section will at first leave 30% of the data as a test set. Then, it will filter out from that test set the users and items which were not in the remaining 70% which was set as training data. This test set will be used to evaluate ranking-based recommendation metrics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in training data: 12,274,957\n",
      "Number of entries in test data: 5,245,312\n",
      "Number of users in training data: 358,857\n",
      "Number of users in test data: 358,716\n",
      "Number of items in training and test data: 147,065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(lfm, test_size=.3)\n",
    "df_train = df_train.copy()\n",
    "users_train = np.unique(df_train.UserId.to_numpy())\n",
    "items_train = np.unique(df_train.ItemId.to_numpy())\n",
    "df_test = df_test.loc[df_test.UserId.isin(users_train) &\n",
    "                      df_test.ItemId.isin(items_train)]\n",
    "df_train[\"UserId\"] = pd.Categorical(df_train.UserId, users_train).codes\n",
    "df_train[\"ItemId\"] = pd.Categorical(df_train.ItemId, items_train).codes\n",
    "df_test[\"UserId\"] = pd.Categorical(df_test.UserId, users_train).codes\n",
    "df_test[\"ItemId\"] = pd.Categorical(df_test.ItemId, items_train).codes\n",
    "users_test = np.unique(df_test.UserId.to_numpy())\n",
    "\n",
    "print(\"Number of entries in training data: {:,}\".format(df_train.shape[0]))\n",
    "print(\"Number of entries in test data: {:,}\".format(df_test.shape[0]))\n",
    "print(\"Number of users in training data: {:,}\".format(users_train.shape[0]))\n",
    "print(\"Number of users in test data: {:,}\".format(users_test.shape[0]))\n",
    "print(\"Number of items in training and test data: {:,}\".format(items_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking metrics for evaluation\n",
    "\n",
    "The models fit here will be evaluated by AUC and P@5, calculated for individual users and then averaged across a random sample of 1,000 users. These metrics are calculated for each user separately, by taking the entries in the hold-out test set as a positive class, entries which are neither in the training or test sets as a negative class, and producing predictions for all the entries that were not in the training set - the idea being that models which tend to rank highest the songs that the users ended up listening are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "## Note: this is a computationally inefficient implementation of the\n",
    "## test metrics, not recommended to use outside of this notebook\n",
    "def print_ranking_metrics(A, B, df_train, df_test, users_test,\n",
    "                          nusers=1000, top_n=5, seed=1,\n",
    "                          njobs=-1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array(m, k)\n",
    "        The user-factor matrix.\n",
    "    B : array(n, k)\n",
    "        The item-factor matrix\n",
    "    df_train : DataFrame(n_train, [user, item, value])\n",
    "        The training triplets.\n",
    "    df_test : DataFrame(n_test, [user, item, value])\n",
    "        The hold-out triplets.\n",
    "    n_user : int\n",
    "        Number of users to sample.\n",
    "    top_n : int\n",
    "        Number of top-ranked items to calculate precision.\n",
    "    seed : int\n",
    "        Random seed used to select the users.\n",
    "    njobs : int\n",
    "        Number of jobs to run in parallel.\n",
    "    \"\"\"\n",
    "    n_users = A.shape[0]\n",
    "    n_items = B.shape[0]\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    chosen_users = rng.choice(users_test, size=nusers, replace=False)\n",
    "    all_train = df_train.loc[df_train.UserId.isin(chosen_users)]\n",
    "    all_test = df_test.loc[df_test.UserId.isin(chosen_users)]\n",
    "    \n",
    "    def metrics_single_user(user):\n",
    "        ypos = all_test.ItemId.loc[all_test.UserId == user].to_numpy()\n",
    "        ytrain = all_train.ItemId.loc[all_train.UserId == user].to_numpy()\n",
    "        yneg = np.setdiff1d(np.arange(n_items), np.r_[ypos, ytrain])\n",
    "        ytest = np.r_[yneg, ypos]\n",
    "        yhat = B[ytest].dot(A[user])\n",
    "        auc = roc_auc_score(np.r_[np.zeros(yneg.shape[0]),\n",
    "                                  np.ones(ypos.shape[0])],\n",
    "                            yhat)\n",
    "        topN = np.argsort(-yhat)[:top_n]\n",
    "        p_at_k = np.mean(topN >= yneg.shape[0])\n",
    "        p_at_k_rnd = ypos.shape[0] / ytest.shape[0] ## <- baseline\n",
    "        return auc, p_at_k, p_at_k_rnd\n",
    "\n",
    "    res_triplets = Parallel(n_jobs = njobs)\\\n",
    "                    (delayed(metrics_single_user)(u) \\\n",
    "                        for u in chosen_users)\n",
    "\n",
    "    res_triplets = np.array(res_triplets)\n",
    "    auc = np.mean(res_triplets[:,0])\n",
    "    p_at_k = np.mean(res_triplets[:,1])\n",
    "    p_at_k_rnd = np.mean(res_triplets[:,2])\n",
    "    print(\"AUC: %.4f [random: %.2f]\" % (auc, 0.5))\n",
    "    print(\"P@%d: %.4f [random: %.4f]\" % (top_n,\n",
    "                                         p_at_k,\n",
    "                                         p_at_k_rnd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "** *\n",
    "This section will fit and evaluate the Poisson factorization model fit with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poismf import PoisMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oriented towards speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.2 s, sys: 204 ms, total: 57.4 s\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_fast = PoisMF(reindex=False, method=\"pg\", use_float=False,\n",
    "                    k=10, niter=10, maxupd=1, l2_reg=1e9)\\\n",
    "                .fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9521 [random: 0.50]\n",
      "P@5: 0.0944 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(model_fast.A, model_fast.B,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster, but still not-so-good quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 44s, sys: 4.06 s, total: 36min 48s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_balanced = PoisMF(reindex=False, method=\"cg\", use_float=False,\n",
    "                        k=50, niter=30, maxupd=5, l2_reg=1e4)\\\n",
    "                    .fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9805 [random: 0.50]\n",
      "P@5: 0.1496 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(model_balanced.A, model_balanced.B,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good quality and producing sparse factors, but slow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 18min 43s, sys: 3.61 s, total: 1h 18min 46s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Note: 'maxupd' for 'tncg' means 'maxfneval'\n",
    "model_good = PoisMF(reindex=False, method=\"tncg\", use_float=True,\n",
    "                    early_stop=False, reuse_prev=True,\n",
    "                    k=50, niter=10, maxupd=750, l2_reg=1e3)\\\n",
    "                .fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9622 [random: 0.50]\n",
      "P@5: 0.1666 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(model_good.A, model_good.B,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 56min 4s, sys: 6.43 s, total: 2h 56min 10s\n",
      "Wall time: 12min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Note: 'maxupd' for 'tncg' means 'maxfneval'\n",
    "model_good = PoisMF(reindex=False, method=\"tncg\", use_float=False,\n",
    "                    early_stop=False, reuse_prev=False,\n",
    "                    k=50, niter=10, maxupd=750, l2_reg=1e3)\\\n",
    "                .fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9642 [random: 0.50]\n",
      "P@5: 0.1748 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(model_good.A, model_good.B,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In this case, it's possible to increase P@5 at the expense of AUC by decreasing  the regulatization parameter)\n",
    "** *\n",
    "### Sparse factors\n",
    "\n",
    "Verifying that the obtain latent factors are indeed sparse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.37548055, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.22496463, 0.        , 0.        , 0.3023136 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08906156, 0.24148953, 0.07967508, 0.50097793,\n",
       "       0.        , 0.        , 0.        , 0.4223403 , 0.        ,\n",
       "       0.        , 0.        , 0.2862075 , 0.        , 0.        ,\n",
       "       0.36616151, 0.        , 0.        , 0.56081352, 0.10372217,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.1807172 , 0.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_good.A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of zero-valued entries in A: 83.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of zero-valued entries in A: %.2f%%\" %\n",
    "      float((model_good.A == 0.).mean() * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of zero-valued entries in B: 96.29%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of zero-valued entries in B: %.2f%%\" %\n",
    "      float((model_good.B == 0.).mean() * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction API\n",
    "** *\n",
    "Ranking top-N items IDs for a given user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146868,      0,  76670,  63927,  61023], dtype=uint64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_good.topN(user = 2, n = 5,\n",
    "                exclude = df_train.ItemId.loc[df_train.UserId==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(These numbers correspond to the IDs of the items in the data that was passed)\n",
    "\n",
    "If it were a new user - note that the obtained latent factors will differ slightly and it might affect the ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,  96069,  61023, 141861,  76670], dtype=uint64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_good.topN_new(df_train.loc[df_train.UserId==2], n = 5,\n",
    "                     exclude = df_train.ItemId.loc[df_train.UserId==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting new (user,item) combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Predicts triplets (3,4), (3,5), (10,11)\n",
    "model_good.predict(user=[3,3,3], item=[3,4,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining latent factors for new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52425574, 0.        , 0.        , 0.04752998, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.48260419, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.28941052,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.11441212,\n",
       "       0.04037867, 0.        , 0.        , 0.        , 0.03104742,\n",
       "       0.03014911, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_good.predict_factors(df_train.loc[df_train.UserId==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison against other factorization models\n",
    "** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, csr_matrix, csc_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from hpfrec import HPF ### <- Bayesian version\n",
    "from cmfrec import MostPopular\n",
    "\n",
    "## Note: package implicit takes a matrix of shape [items, users]\n",
    "## Other packages take a matrix of shape [users, items]\n",
    "Xcoo = coo_matrix((df_train.Count, (df_train.UserId, df_train.ItemId)))\n",
    "Xcoo_T = Xcoo.T\n",
    "Xcsr_T = csr_matrix(Xcoo_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 35.9 ms, total: 188 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_personalized = MostPopular(implicit=True).fit(Xcoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9522 [random: 0.50]\n",
      "P@5: 0.0938 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(np.ones((Xcoo.shape[0],1)),\n",
    "                      non_personalized.item_bias_.reshape((-1,1)),\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3980b50ace14b54b82dc0c0cdc67d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6min 53s, sys: 4.64 s, total: 6min 57s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ials = AlternatingLeastSquares(factors=50, regularization=0.01,\n",
    "                               dtype=np.float64, iterations=15)\n",
    "ials.fit(Xcsr_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9768 [random: 0.50]\n",
      "P@5: 0.2026 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(ials.user_factors, ials.item_factors,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa711d4b225a4995b6d2d71f931957ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 34min 12s, sys: 5.36 s, total: 34min 18s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bpr = BayesianPersonalizedRanking(factors=50, learning_rate=0.01,\n",
    "                                  regularization=0.01, dtype=np.float64,\n",
    "                                  iterations=100)\n",
    "bpr.fit(Xcoo_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9513 [random: 0.50]\n",
      "P@5: 0.0986 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(bpr.user_factors, bpr.item_factors,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 39s, sys: 16.4 s, total: 27min 55s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hpf = HPF(k=50, verbose=False, use_float=False).fit(Xcoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9720 [random: 0.50]\n",
      "P@5: 0.1190 [random: 0.0001]\n"
     ]
    }
   ],
   "source": [
    "print_ranking_metrics(hpf.Theta, hpf.Beta,\n",
    "                      df_train, df_test, users_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *\n",
    "# References\n",
    "\n",
    "* Cortes, David. \"Fast Non-Bayesian Poisson Factorization for Implicit-Feedback Recommendations.\" arXiv preprint arXiv:1811.01908 (2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
